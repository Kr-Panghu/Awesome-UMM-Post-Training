# Awesome-UMM-Post-Training [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) <!-- omit in toc -->

This is a repository for organizing papers, codes and other resources related to **post-training methods** for **unified multimodal models (UMM)**.

### Papers

+ [Architecture Decoupling Is Not All You Need For Unified Multimodal Model](https://arxiv.org/abs/2511.22663) (Nov. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2511.22663) [![Star](https://img.shields.io/github/stars/zhengdian1/AIA.svg?style=social&label=Star)](https://github.com/zhengdian1/AIA) 


+ [UniGame: Turning a Unified Multimodal Model Into Its Own Adversary](https://arxiv.org/abs/2511.19413) (Nov. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2511.19413) [![Star](https://img.shields.io/github/stars/AIFrontierLab/UniGame.svg?style=social&label=Star)](https://github.com/AIFrontierLab/UniGame)

+ [UniRL-Zero: Reinforcement Learning on Unified Models with Joint Language Model and Diffusion Model Experts](https://arxiv.org/abs/2510.17937v1) (Oct. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2510.17937v1) [![Star](https://img.shields.io/github/stars/G-U-N/UniRL.svg?style=social&label=Star)](https://github.com/G-U-N/UniRL) 

+ [SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models](https://arxiv.org/abs/2510.12784) (Oct. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2510.12784) [![Star](https://img.shields.io/github/stars/WayneJin0918/SRUM.svg?style=social&label=Star)](https://github.com/WayneJin0918/SRUM) 


+ [Reconstruction Alignment Improves Unified Multimodal Models](https://arxiv.org/abs/2509.07295) (Sep. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2509.07295) [![Star](https://img.shields.io/github/stars/HorizonWind2004/reconstruction-alignment.svg?style=social&label=Star)](https://github.com/HorizonWind2004/reconstruction-alignment)


+ [Unified Multimodal Model as Auto-Encoder](https://arxiv.org/abs/2509.09666) with <a href="https://github.com/PKU-YuanGroup/UAE?tab=readme-ov-file#-evaluation-framework">ðŸ“Š UniBench</a> (Sep. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2509.09666) [![Star](https://img.shields.io/github/stars/PKU-YuanGroup/UAE.svg?style=social&label=Star)](https://github.com/PKU-YuanGroup/UAE) 


+ [Turning Internal Gap into Self-Improvement: Promoting the Generation-Understanding Unification in MLLMs](https://arxiv.org/abs/2507.16663) (Jul. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2507.16663)


+ [UniRL: Self-Improving Unified Multimodal Models via Supervised and Reinforcement Learning](https://arxiv.org/abs/2505.23380v1) (May. 2025, arXiv) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2505.23380v1) [![Star](https://img.shields.io/github/stars/showlab/UniRL.svg?style=social&label=Star)](https://github.com/showlab/UniRL) 

+ [Co-Reinforcement Learning for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2505.17534) (May. 2025, NeurIPS 2025) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2505.17534) [![Star](https://img.shields.io/github/stars/mm-vl/ULM-R1.svg?style=social&label=Star)](https://github.com/mm-vl/ULM-R1)

+ [Unified Reward Model for Multimodal Understanding and Generation](https://arxiv.org/abs/2503.05236) (May. 2025, NeurIPS 2025) [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2503.05236) [![Star](https://img.shields.io/github/stars/CodeGoat24/UnifiedReward.svg?style=social&label=Star)](https://github.com/CodeGoat24/UnifiedReward)